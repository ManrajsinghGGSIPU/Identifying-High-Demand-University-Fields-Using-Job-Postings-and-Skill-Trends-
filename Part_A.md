Big Data and Analytics – Assignment 1A: Project Report
Title: Identifying High-Demand University Fields Using Job Postings and Skill Trends
(2024)
Name: Manraj Singh
1. Introduction and Problem Description
With the current ever-changing world, technology, automatization, and worldwide trends are
transforming sectors. The question students, teachers, and employers are keen to see answered
is this: Of all the fields of study at this university, e.g. IT, healthcare, construction, or education,
which will provide them with the best source of employment in the next five years? It is
essential to select a field in which students are bound to get good careers, as it is essential to
universities to design good courses and to employers to get skilled workers
My project will aims to answer the following main question:
Key Research Question:
Based on current industry trends, which university fields of study show the strongest job
market signals for graduates over the next five years?
This question matters because:
 To develop successful careers, the students must choose disciplines that have good
employment opportunities.
 Colleges have to revise their curriculum to suit students in the jobs on demand.
 Employers are interested to know the places where they are training their future talent
to address their hiring needs.
Backup Research Question:
Which technical and soft skills are growing the fastest in demand across industries?
This project will therefore give explicit information through the study of job ads and the trends
of skills to impact the decisions of the students, educators, and businesses.
2. Dataset Identification and Description
A huge and elaborate set of data would be necessary to address such questions. The selected
data are:
Primary Dataset:
 Name: LinkedIn Jobs and Skills (2024)
 Source: Kaggle
 Link: https://www.kaggle.com/datasets/asaniczka/1-3m-linkedin-jobs-and-skills-2024
 Fields: Job Title, Industry, Job Description, Required Skills, Company Name,
Location, Job Function, Seniority Level
Such a dataset is the best to work with since it provides more than 1.3 million job postings of
2024 and represents a general opinion of recruiters across the world. It is made up of structured
data (such as job titles and industry) as well as unstructured data (such as job descriptions) and
this data can be examined to produce patterns.
Big Data Characteristics (The 4 Vs):
 Volume: The job record (more than 1.3 million jobs) is considered large enough to
unveil credible patterns.
 Velocity: This is current data of the year 2024 and it is helpful to make direction about
the coming years.
 Variety: Both the text and categorical variable types of information are presented in
the dataset and may involve diverse information, including job titles, skills, and
industries.
 Veracity: The information gathered is more or less reliable as it is generated by
LinkedIn, however, there might be some mistakes or repetitions which are supposed
to be cleaned.
The dataset will be useful in the mapping of job roles and skill to the university fields which
can give a clear picture of the demand fields..
3. Initial Data Processing and Quality Assessment
Before analyzing the dataset, it must be cleaned and prepared to ensure accurate results. The
following steps will be taken:
Data Cleaning:
 Remove incomplete entries: Delete records with missing job titles, descriptions, or
skills.
 Normalize job titles: Standardize variations (e.g., “Software Engineer” and “Software
Developer”) for consistency.
 Clean skill lists: Remove duplicates and correct spelling errors in skills.
Text-Based Categorization:
 Use Natural Language Processing (NLP) tools to analyze job descriptions and skills.
 Map job roles and skills to university fields (e.g., “Python programming” maps to IT,
“patient care” maps to Healthcare).
Feature Engineering:
 Create a new column called Field of Study to link jobs to academic fields.
 Categorize skills into hard skills (e.g., coding, data analysis) and soft skills (e.g.,
teamwork, communication).
Data Consolidation:
 Organize the dataset into a clean table with labeled columns for easy analysis.
Handling Class Imbalance:
 Some fields (like IT) may dominate the dataset, while others (like construction) may be
underrepresented. Adjust visualizations to fairly represent all fields.
Expected Challenges:
 Inconsistent job titles: Use text normalization to group similar titles.
 Missing industry information: Infer industries from job descriptions using NLP.
 No direct education field: Map skills to fields using external frameworks like ESCO
or O*NET.
4. Refined Problem and Plan
After reviewing the dataset and research goals, the main question has been refined for clarity:
Refined Research Question:
How can job posting trends and skill requirements from large datasets predict which
university fields will be in most demand in the next five years?
It seeks to answer the question of what subjects of study (IT, medical, construction, etc.) are
becoming trendy on the basis of the vacancies posted as well as the abilities that the potential
employers are demanding. With the content analysis of extensive job market data we expect to
forecast fields in the university to have good employment opportunity in future. This has the
potential to assist the students in making the correct course selections and inform universities
in fixing their programs to the world of work.
Next Steps for Analysis:
1. Data Cleaning & Preprocessing: The backup plan utilizes such that the project can
still be pursued despite deficiency in the primary dataset use Python libraries such as
pandas and numpy to clean and arrange the data.
2. Text Analysis & Skill Mapping: Use NLP such as spaCy or NLTK tools to skim skills
and associate them to the fields. Take advantages of keyword matching to provide
accuracy.
3. Trend Visualization: Produce graphs created in Tableau or Matplotlib to reveal how
many jobs followed by skill trends over the field.
4. Skill Frequency Analysis: Create CountVectorizer to count the number of occurrences
of skills in job postings. Plot outputs in order to determine rapidly increasing skills.
5. Forecasting Field Demand: Predict job demand by setting up models or charts (time
series such as ARIMA or Prophet) to be in demand in each field in the course of the
next five years.
6. Clustering Similar Fields/Skills: Group related fields or skills using clustering
techniques like K-means or DBSCAN to uncover patterns.
Evaluation Metrics:
 Job count per field: Measure how many jobs are posted for each field.
 Top growing skills: Identify skills with the fastest increase in demand.
 Emerging skills: Highlight new skills not traditionally taught in universities.
Backup Plan:
If the LinkedIn dataset is too noisy or lacks clear indicators:
 Switch to alternative datasets like Job-SDF or PayScale API. https://github.com/JobSDF/benchmark/tree/main/dataset
 Adjust the research question to: “What skills are most frequently associated with job
growth in different industries over time?”
 This backup will secure the possibility of the project going on in case the primary
dataset has its limitations.
5. Conclusion
The current project builds the basis of discovering the fields in universities, which have high
demand, based on analysing job adverts and trends of skills. What has been done in this
initial phase is:
 Stated a feasible research question regarding future employment of university
disciplines.
 Chose a huge, skill-and-data-enriched LinkedIn file.
 Anticipated action to clean, process and analsze the data.
 Proposed a strategy to map skills to academic fields.
 Made contingency plans on how to deal with dataset constraints.
With the accomplishment of this project, useful information will be availed to assist learners
in selecting rewarding careers, university developing appropriate courses and employers being
able to hire competent graduates. This will help close the gap between the education and the
needs of the industries, and this will help align future job market much better.
6. References
Asaniczka, A. (2024) 1.3M LinkedIn Jobs and Skills Dataset. Kaggle. Available at:
https://www.kaggle.com/datasets/asaniczka/1-3m-linkedin-jobs-and-skills-2024 (Accessed:
15 June 2025).
European Commission (2023) ESCO: European Skills, Competences, Qualifications and
Occupations. Available at: https://ec.europa.eu/esco/portal (Accessed: 15 June 2025).
National Center for ONET Development (2023) ONET Online: Occupational Information
Network. Available at: https://www.onetonline.org (Accessed: 15 June 2025).
Job-SDF (2024) Job-SDF Benchmark: A Large-Scale Dataset for Job Skill Demand
Forecasting. GitHub. Available at: https://github.com/Job-SDF/benchmark (Accessed: 15
June 2025). 
